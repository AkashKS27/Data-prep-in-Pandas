{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.1"
    },
    "colab": {
      "name": "WPI_Assignment_DL_1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyKSyMwA5GnC"
      },
      "source": [
        "# Deep Neural For Autonomous Vehicles\n",
        "\n",
        "**Module 1 Assignment: Data Preparation in Pandas**\n",
        "\n",
        "**Student Name: Your Name**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWjwKyzU5GnK"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "For this assignment you will use the **reg-30-spring-2018.csv** dataset.\n",
        "\n",
        "For this assignment, load and modify the data set.\n",
        "\n",
        "Modify the dataset as follows:\n",
        "\n",
        "* Drop the *id* column.\n",
        "* Replace the missing values (NA's) in the *width* column with the median width. (obviously, do not use the NA's to calculate the median for this replacement)\n",
        "* Replace the following columns with their z-score: *landings*, *number*, and *pack*.\n",
        "* All other columns should be left unchanged.\n",
        "* If is unlikely that you will get any submit warnings if you completed this assignment correctly.\n",
        "* Your submitted dataframe will have these columns: distance, height, landings, number, pack, age,  usage, region, weight, item, volume, width, max, power, size, target.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-lXp9UG5GnL"
      },
      "source": [
        "# Helpful Functions\n",
        "\n",
        "You will see these at the top of every module and assignment.  These are simply a set of reusable functions that we will make use of.  Each of them will be explained as the course progresses. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "JjzCHfBP5GnM"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "import requests\n",
        "import base64\n",
        "\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
        "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
        "# each target value.\n",
        "def encode_text_single_dummy(df, name, target_values):\n",
        "    for tv in target_values:\n",
        "        l = list(df[name].astype(str))\n",
        "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
        "        name2 = \"{}-{}\".format(name, tv)\n",
        "        df[name2] = l\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column.  Is it really this hard? :(\n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ga2F0jMx5GnN"
      },
      "source": [
        "# Assignment #1 Sample Code\n",
        "\n",
        "The following code provides a starting point for this assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kA9rDGIi5GnO"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import shutil\n",
        "import requests\n",
        "import base64\n",
        "\n",
        "file = '/content/reg-30-spring-2018.csv'\n",
        "\n",
        "# Begin assignment\n",
        "path = \"./data/\"\n",
        "\n",
        "filename_read = os.path.join(path,\"reg-30-spring-2018.csv\")\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "# Drop ID\n",
        "df.drop([\"id\"], axis = 1, inplace = True) \n",
        "# Replace width NA's with median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "missing_median(df, \"width\")\n",
        "# ZScore\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "encode_numeric_zscore(df, \"landings\")\n",
        "encode_numeric_zscore(df, \"number\")\n",
        "encode_numeric_zscore(df, \"pack\")\n",
        "\n",
        "# You might want to save to a CSV, just to look at\n",
        "df.to_csv('1.csv',index=False)\n"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}